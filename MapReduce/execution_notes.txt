Práctica de Sistemas Distribuidos de Procesamiento de Datos: Análisis de 
sentimientos con Hadoop
Autor: Miguel Ángel Monjas Llorente

Map Reduce Streaming
====================
====================

Se proporcionan dos conjuntos de scripts, basados ambos en MapReduce Streaming:
- mapper_ng.py y reducer_ng.py para la ejecución en local y en Hortonworks
- mapper_aws.py, reducer_aws y reducer_aws_02 para la ejecución en AWS EMR.

También se requieren dos ficheros auxiliares: us_states.txt y AFINN-111.txt.
El primero contiene las abreviaturas y el nombre completo de los 

Los ficheros de datos de Twitter sobre los que se ejecutan las tareas se 
denominan dumpx.txt, en donde 'x' es un entero. En total, son unos 8 Gbytes de
datos.

Existen dos modos de ejecución, dependiendo de si se requieren los datos
relativos al sentimiento por estado o a los trending topics. La opción por 
defecto es la relativa a los estados de Estados Unidos. Si se quiere hallar
los diez trending topics se invoca, sobre el reducer, usando el argumento type
con el valor hashtags.

En ambos casos, la salida será un fichero CSV. En el caso del sentimiento por
estado, cada línea será del tipo estado;número_de_tweets;sentimiento_medio. En
el caso de los hashtags, se sigue también un formato CSV del tipo 
hashtag;número_de_apariciones

Ejecución Map Reduce Streaming local
====================================
La ejecución local en Windows 10 con git bash es de la siguiente forma:
$ cat dump4.txt | ./mapper_ng.py | sort | ./reducer_ng.py > results_00.txt

La ejecución con la shell nativa de Windows es similar:

D:\>type dump4.txt | mapper_ng.py | sort | reducer_ng.py > results_10.txt

Las ejecuciones para extraer los trending topics incluirán el argumento type:

$ cat dump4.txt | ./mapper_ng.py | sort | ./reducer_ng.py --type hashtags > results_00.txt
D:\>type dump4.txt | mapper_ng.py | sort | reducer_ng.py --type hashtags > results_10.txt


Ejecución Map Reduce Streaming en Horton Works
==============================================

Antes de poder utilizar la máquina virtual de Hortonworks, hay que efectuar
algunos procedimientosç:

1. Es necesario inicializar el sistema de ficheros HDFS:
hdfs dfs -mkdir /user/<username>

Como el nombre de usuario es root:
hdfs dfs -mkdir /user/root

2. El fichero jar se encuentra en /usr/hdp/current/hadoop-mapreduce-client

3. El nombre del cluster es sandbox.hortonworks.com (puede sacarse de 
/etc/hosts). También puede usarse 127.0.0.2.

4. Los scripts deben hacerse ejecutables:
chmod a+x ./mapper_ng.py
chmod a+x ./reducer_ng.py

5. Antes de ejecutarlos hay que transformar el formato:
dos2unix mapper_ng.py
dos2unix reducer_ng.py

6. Los ficheros dumpx.txt deben copiarse al sistema de ficheros HDFS. Los
ficheros auxiliares no hace falta copiarlos.

7. Ejemplo de ejecución, para el caso de los estados:
[root@sandbox ~]# hadoop jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar 
-files mapper_ng.py,reducer_ng.py,AFINN-111.txt,us_states.txt 
-mapper mapper_ng.py -reducer reducer_ng.py 
-input hdfs://sandbox.hortonworks.com/user/root/input/streaming/dump4.txt
-output hdfs://sandbox.hortonworks.com/user/root/output/streaming_01

8. De forma similar, para el caso de los trending topics:
[root@sandbox ~]# hadoop jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar    
-files mapper_ng.py,reducer_ng.py,AFINN-111.txt                                
-mapper mapper_ng.py -reducer 'reducer_ng.py --type hashtags'                                   
-input hdfs://sandbox.hortonworks.com/user/root/input/streaming/dump4.txt                
-output hdfs://sandbox.hortonworks.com/user/root/output/streaming_02                         

9. Examinar los resultados:

[root@sandbox ~]# hdfs dfs -getmerge hdfs://sandbox.hortonworks.com/user/root/output/streaming_01 ./results_01.txt

Ejecución Map Reduce Streaming en EMR AWS
=========================================

Se muestra en la memoria.

MRJob
=====

Se proporciona un único script: mrjob_twitter.py. Su uso se muestra en la memoria.
